{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "# Baseline Model and Dataset\n",
    "\n",
    "os.system(\"pwd\")\n",
    "from dotPyfiles.LeNet import *\n",
    "from dotPyfiles.class_imbalance_dataset import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "os.system(\"pwd\")\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'errorbar.capsize': 5})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_PARAMS = {\n",
    "    'lr' : 1e-3,\n",
    "    'batch_size' : 100,\n",
    "    'num_iterations' : 2000,\n",
    "}\n",
    "data_loader = get_mnist_loader(H_PARAMS['batch_size'], classes=[8, 0], proportion=0.8, mode=\"train\")\n",
    "test_loader = get_mnist_loader(H_PARAMS['batch_size'], classes=[8, 0], proportion=0.5, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_avail(x, requires_grad=True):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x, requires_grad=requires_grad)\n",
    "\n",
    "\n",
    "loaded_imgs = gpu_avail(data_loader.dataset.data_val, requires_grad=False)\n",
    "loaded_lbls = gpu_avail(data_loader.dataset.labels_val, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Lemodel():\n",
    "    model = LeNet(n_out=1)\n",
    "    # model = VGGmodel(n_out=1)\n",
    "    # model = remodel(n_out=1)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        # torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.params(),lr=H_PARAMS[\"lr\"])\n",
    "    return model, optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Training Function - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "total_loss = []\n",
    "step_size_for_fig = 100\n",
    "\n",
    "model, optimizer = get_Lemodel()\n",
    "model_l = 0\n",
    "a = 0.9\n",
    "accuracy_log = []\n",
    "preds = []\n",
    "\n",
    "iters = H_PARAMS['num_iterations']\n",
    "start_time = time.time()\n",
    "for i in tqdm(range(iters)):\n",
    "    model.train()\n",
    "    img, labels = next(iter(data_loader))\n",
    "\n",
    "    img = gpu_avail(img, requires_grad=False)\n",
    "    labels = gpu_avail(labels, requires_grad=False)\n",
    "    # labels = labels.unsqueeze(1)\n",
    "\n",
    "    model_output = model(img)\n",
    "    cel = F.binary_cross_entropy_with_logits(model_output, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cel.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model_l = a * model_l + (1 - a) * cel.item()\n",
    "    \n",
    "    eval = model_l/(1 - a**(i+1))\n",
    "    total_loss.append(eval)\n",
    "    \n",
    "    if i % step_size_for_fig == 0:\n",
    "        pred = []\n",
    "        model.eval()\n",
    "        \n",
    "        for itr,(test_img, test_label) in enumerate(test_loader):\n",
    "            test_img = gpu_avail(test_img, requires_grad=False)\n",
    "            test_label = gpu_avail(test_label, requires_grad=False)\n",
    "            \n",
    "            output = model(test_img)\n",
    "            predicted = (F.sigmoid(output) > 0.5)\n",
    "            float_prediction = (predicted.int() == test_label.int()).float()\n",
    "            preds.append(float_prediction)\n",
    "        \n",
    "        accuracy = torch.cat(preds,dim=0).mean()\n",
    "        accuracy_log.append(np.array([i,accuracy])[None])\n",
    "        \n",
    "    \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "        ax1, ax2 = axes.ravel()\n",
    "\n",
    "        ax1.plot(total_loss, label='total_loss')\n",
    "        ax1.set_ylabel(\"Losses\")\n",
    "        ax1.set_xlabel(\"Iteration\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        history_of_accuracies = np.concatenate(accuracy_log, axis=0)\n",
    "        ax2.plot(history_of_accuracies[:,0],history_of_accuracies[:,1])\n",
    "        # ax2.title(\"Regular Training - 80% Imbalance\")\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_xlabel('Iteration')\n",
    "        # plt.plot(total_loss, label=\"Net Loss for 2k iterations\")\n",
    "        # plt.show()\n",
    "        # plt.plot(acc_log[:,0], acc_log[:,1])\n",
    "        # # plt.label(\"Accuracy showing differentiation between '8' and '0'\")\n",
    "        plt.show()\n",
    "print(f\"Diff = {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_of_accuracies[:,0],history_of_accuracies[:,1])\n",
    "plt.title(\"Regular Training - 80% Imbalance\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.linspace(-10, 10, 1000, requires_grad=True)\n",
    "w = torch.tensor([0.1], requires_grad=True)\n",
    "\n",
    "swish_output = x * torch.sigmoid(w * x)\n",
    "swish_output.sum().backward()\n",
    "swish_grad = x.grad.clone()\n",
    "x.grad.zero_()\n",
    "\n",
    "relu_output = torch.relu(w * x)\n",
    "relu_output.sum().backward()\n",
    "relu_grad = x.grad.clone()\n",
    "x.grad.zero_()\n",
    "\n",
    "plt.plot(x.detach().numpy(), swish_grad.detach().numpy(), label='Swish')\n",
    "plt.plot(x.detach().numpy(), relu_grad.detach().numpy(), label='ReLU')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Gradient')\n",
    "plt.title(\"Vanishing Gradient Problem\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Paper Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reAlgo():\n",
    "\n",
    "    model, optimizer = get_Lemodel()\n",
    "    meta_losses_clean, total_loss, history_of_accuracies = [],[],[]\n",
    "    step_size_for_fig = 100\n",
    "    iters = H_PARAMS['num_iterations']\n",
    "    a = 0.9\n",
    "    meta_l,model_l, MIN = 0,0,0\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(iters)):\n",
    "        model.train()\n",
    "        img, labels = next(iter(data_loader))\n",
    "        meta_model = LeNet(n_out=1)\n",
    "        meta_model.load_state_dict(model.state_dict())\n",
    "\n",
    "        if torch.cuda.is_available():meta_model.cuda()\n",
    "\n",
    "        img = gpu_avail(img, requires_grad=False)\n",
    "        labels = gpu_avail(labels, requires_grad=False)\n",
    "\n",
    "        meta_model_out  = meta_model(img)\n",
    "        cel = F.binary_cross_entropy_with_logits(meta_model_out,labels, reduce=False)\n",
    "\n",
    "        epsilon = gpu_avail(torch.zeros(cel.size()))\n",
    "        sum_MM_out = torch.sum(cel* epsilon)\n",
    "\n",
    "        meta_model.zero_grad()\n",
    "        \n",
    "        grads = torch.autograd.grad(sum_MM_out, (meta_model.params()), create_graph=True)\n",
    "        meta_model.update_params(H_PARAMS['lr'], source_params=grads)\n",
    "        \n",
    "        meta_model_prime = meta_model(loaded_imgs)\n",
    "\n",
    "        cel_prime = F.binary_cross_entropy_with_logits(meta_model_prime,loaded_lbls)\n",
    "        epsilon_prime = torch.autograd.grad(cel_prime, epsilon, only_inputs=True)[0]\n",
    "        \n",
    "        w = torch.clamp(-epsilon_prime,min=MIN)\n",
    "        LNorm = torch.sum(w)\n",
    "\n",
    "        meta_model_out = model(img)\n",
    "        cost = F.binary_cross_entropy_with_logits(meta_model_out, labels, reduce=False)\n",
    "\n",
    "\n",
    "        if LNorm != 0:\n",
    "            w = w / LNorm\n",
    "        sum_MM_out = torch.sum(cost * w)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sum_MM_out.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        meta_l = a * meta_l + (1 - a) * cel_prime.item()\n",
    "        meta_losses_clean.append(meta_l / (1 - a**(i+1)))\n",
    "\n",
    "        model_l = a *model_l + (1 - a)* sum_MM_out.item()\n",
    "        total_loss.append(model_l/(1 - a**(i+1)))\n",
    "\n",
    "        if i % step_size_for_fig == 0:\n",
    "            model.eval()\n",
    "\n",
    "            preds = []\n",
    "            for itr,(test_img, test_label) in enumerate(test_loader):\n",
    "                test_img = gpu_avail(test_img, requires_grad=False)\n",
    "                test_label = gpu_avail(test_label, requires_grad=False)\n",
    "\n",
    "                output = model(test_img)\n",
    "                predicted = (F.sigmoid(output) > 0.5)\n",
    "                float_prediction = (predicted.int() == test_label.int()).float()\n",
    "                preds.append(float_prediction)\n",
    "\n",
    "            accuracy = torch.cat(preds,dim=0).mean()\n",
    "            history_of_accuracies.append(np.array([i,accuracy])[None])\n",
    "\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "            ax1, ax2 = axes.ravel()\n",
    "\n",
    "            ax1.plot(meta_losses_clean, label='meta_losses_clean')\n",
    "            ax1.plot(total_loss, label='total_loss')\n",
    "            ax1.set_ylabel(\"Losses\")\n",
    "            ax1.set_xlabel(\"Iteration\")\n",
    "            ax1.legend()\n",
    "\n",
    "            logs = np.concatenate(accuracy_log, axis=0)\n",
    "            ax2.plot(logs[:,0],logs[:,1])\n",
    "            ax2.set_title('Re-weighted Training - 80% Imbalance')\n",
    "            ax2.set_ylabel('Accuracy')\n",
    "            ax2.set_xlabel('Iteration')\n",
    "            # plt.show()\n",
    "\n",
    "    mean = np.mean(logs[-6:-1, 1])\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "num_repeats = 1\n",
    "# proportions = [0.9,0.95, 0.98, 0.99, 0.995]\n",
    "# proportions = [0.8]\n",
    "# proportions = [0.9,0.95,0.99]\n",
    "proportions = [(0.90 + 0.95)/2, (0.95+0.99)/2]\n",
    "history_of_accuracies = {}\n",
    "start_time = time.time()\n",
    "batches = H_PARAMS['batch_size']\n",
    "for prop in proportions:\n",
    "    data_loader = get_mnist_loader(batches, classes=[8, 0], proportion=prop, mode=\"train\")\n",
    "    imgs = gpu_avail(data_loader.dataset.data_val, requires_grad=False)\n",
    "    lbls = gpu_avail(data_loader.dataset.labels_val, requires_grad=False)\n",
    "    \n",
    "    for k in range(num_repeats):\n",
    "        accuracy = reAlgo()\n",
    "        if prop in history_of_accuracies:\n",
    "            history_of_accuracies[prop].append(accuracy)\n",
    "        else:\n",
    "            history_of_accuracies[prop] = [accuracy]\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for prop in proportions:\n",
    "    accuracies = history_of_accuracies[prop]\n",
    "    plt.scatter([prop] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for _,v in sorted(history_of_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for _,v in sorted(history_of_accuracies.items())])\n",
    "print(f\"Diff = {time.time() - start_time}\")\n",
    "plt.errorbar(proportions, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Accuracies with imbalance proportions')\n",
    "plt.xlabel('Imbalance Proportions')\n",
    "plt.ylabel('Accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(proportions, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Imbalance Proportion Accuracy')\n",
    "plt.xlabel('Imbalance')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [0.74, 0.52,0.92,0.76,0.61]\n",
    "x = [0.9,0.925,0.95,0.97,0.99]\n",
    "plt.scatter(x,acc)\n",
    "plt.title('Accuracies with imbalance proportions')\n",
    "plt.xlabel('Imbalance Proportions')\n",
    "plt.ylabel('Accuracies')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
